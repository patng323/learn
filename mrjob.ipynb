{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Secondary Sort\n",
    "Secondary using the 3rd key in reverse order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing test.data\n"
     ]
    }
   ],
   "source": [
    "%%writefile test.data\n",
    "4,10,3,Apple\n",
    "2,2,4,Orange\n",
    "6,-1,6,Lemon\n",
    "0,9,18,Apple\n",
    "6,-1,7,Lemon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing test.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test.py\n",
    "\n",
    "'''\n",
    "Input format:\n",
    "....\n",
    "4,10,3,Apple\n",
    "2,2,4,Orange\n",
    "6,-1,6,Lemon\n",
    "0,9,18,Apple\n",
    "6,-1,7,Lemon\n",
    "....\n",
    "'''\n",
    "from mrjob.job import MRJob, MRStep\n",
    "import mrjob\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "def csv_readline(line):\n",
    "    return csv.reader([line]).next()\n",
    "\n",
    "class test(MRJob):\n",
    "    INTERNAL_PROTOCOL = mrjob.protocol.RawProtocol\n",
    "    OUTPUT_PROTOCOL = mrjob.protocol.RawProtocol\n",
    "    \n",
    "    def mapper1(self, line_no, line):\n",
    "        cell = csv_readline(line)\n",
    "        yield cell[0], \"\\t\".join(cell[1:])\n",
    "\n",
    "    def reducer1(self, key, value):\n",
    "        # This reducer does nothing. \n",
    "        # Just pass the mapper's output to the next step.\n",
    "        for v in value:\n",
    "            yield key, v\n",
    "\n",
    "    def reducer2(self, key, value):\n",
    "        yield key, \",\".join(value)\n",
    "    \n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(mapper=self.mapper1,\n",
    "                   reducer=self.reducer1),\n",
    "            MRStep(reducer=self.reducer2,\n",
    "                   jobconf={\n",
    "                    \"stream.num.map.output.key.fields\":\"3\",\n",
    "                    \"mapreduce.job.output.key.comparator.class\":\n",
    "                        \"org.apache.hadoop.mapred.lib.KeyFieldBasedComparator\",\n",
    "                    \"mapreduce.partition.keycomparator.options\":\"-k1,1n -k3,3nr\"\n",
    "                          })]\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    test.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:mrjob.runner:\n",
      "WARNING:mrjob.runner:PLEASE NOTE: Starting in mrjob v0.5.0, protocols will be strict by default. It's recommended you run your job with --strict-protocols or set up mrjob.conf as described at https://pythonhosted.org/mrjob/whats-new.html#ready-for-strict-protocols\n",
      "WARNING:mrjob.runner:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "0\t9\t18\tApple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:mrjob.fs.hadoop:STDERR: 16/02/09 22:18:11 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2\t2\t4\tOrange\n",
      "\n",
      "4\t10\t3\tApple\n",
      "\n",
      "6\t-1\t7\tLemon,-1\t6\tLemon\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from test import test\n",
    "mr_job = test(args=['test.data', '-r', 'hadoop'])\n",
    "with mr_job.make_runner() as runner: \n",
    "    runner.run()\n",
    "    print \"Output:\"\n",
    "    for line in runner.stream_output():\n",
    "        print line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
